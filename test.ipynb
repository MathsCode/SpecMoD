{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/inspire/hdd/global_user/xujiaming-253308120313/anaconda3/envs/specmod/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM,Qwen3ForCausalLM\n",
    "# /share/public/public_models/Qwen3-14B/\n",
    "# /share/others/public_models/Qwen3-14B/\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/inspire/hdd/global_public/public_models/Qwen/Qwen3-8B/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/inspire/hdd/global_public/public_models/Qwen/Qwen3-8B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095c596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(2461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "            {\"role\": \"system\",\n",
    "                \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
    "        ]\n",
    "prompt = 'How are you?'\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": prompt\n",
    "})\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./train_data/vicuna-bench_Qwen3-14B_data_0_2.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1edee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['1']['Token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_name = 'Qwen3-8B'\n",
    "dataset = 'alpaca'\n",
    "begin = 'None'\n",
    "end = 'None'\n",
    "cur_hidden_states = torch.load(f'./train_data/{dataset}_{model_name}_cur_hidden_states_{begin}_{end}.pt')\n",
    "fake_last_hidden_states = torch.load(f'./train_data/{dataset}_{model_name}_fake_last_hidden_states_{begin}_{end}.pt')\n",
    "true_last_hidden_states = torch.load(f'./train_data/{dataset}_{model_name}_true_last_hidden_states_{begin}_{end}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_hidden_states = torch.load(f'./train_data/{dataset}_{model_name}_spec_hidden_states.pt')\n",
    "label = torch.load(f'./train_data/{dataset}_{model_name}_label_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_name = 'Qwen3-8B'\n",
    "dataset = 'alpaca'\n",
    "begin = 'None'\n",
    "end = 'None'\n",
    "train_data = torch.load(f'./train_data/{dataset}_{model_name}_train_data.pt')\n",
    "label = torch.load(f'./train_data/{dataset}_{model_name}_label_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[0] // 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8205c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to(model.device)\n",
    "for i in range(train_data.shape[0]):\n",
    "    last_hidden_states = train_data[i,:,:train_data.shape[-1]//3]\n",
    "    logits = model.lm_head(last_hidden_states)\n",
    "    token = torch.argmax(logits, dim=-1)\n",
    "    embeddings = model.model.embed_tokens(token)\n",
    "    flag = embeddings == train_data[i,:,train_data.shape[-1]//3:train_data.shape[-1]//3 * 2]\n",
    "    if not torch.all(flag):\n",
    "        print(f'{i} Something wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89003c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = train_data[1315,:,:train_data.shape[-1]//3]\n",
    "logits = model.lm_head(last_hidden_states)\n",
    "token = torch.argmax(logits, dim=-1)\n",
    "embeddings = model.model.embed_tokens(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60009e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d09d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1315,:,train_data.shape[-1]//3:train_data.shape[-1]//3 * 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885874d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:,:,:train_data.shape[-1]//3*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['alpaca', 'gsm8k', 'math_infini', 'mt-bench', 'sum', 'vicuna-bench']\n",
    "models = ['Qwen3-8B', 'Qwen3-14B']\n",
    "dataset = 'alpaca'\n",
    "model\n",
    "spec_hidden_states_path = f'./train_data/{dataset}_{model}_spec_hidden_states.pt'\n",
    "cur_hidden_states_path = f'./train_data/{dataset}_{model}_cur_hidden_states_None_None.pt'\n",
    "last_hidden_states_path = f'./train_data/{dataset}_{model}_true_last_hidden_states_None_None.pt'\n",
    "spec_hidden_states = torch.load(spec_hidden_states_path)\n",
    "cur_hidden_states = torch.load(cur_hidden_states_path)\n",
    "last_hidden_states = torch.load(last_hidden_states_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Qwen3-8B', 'Qwen3-14B']\n",
    "datasets = ['alpaca', 'gsm8k', 'sum', 'mt-bench','vicuna-bench', 'math_infini']\n",
    "with open(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ca5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a681edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc145d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63def39c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'torch.Size' object does not support item assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e39893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "model_name = 'Qwen3-8B'\n",
    "dataset = 'alpaca'\n",
    "begin = 'None'\n",
    "end = 'None'\n",
    "with open(f\"./train_data/{dataset}_{model_name}_data_{begin}_{end}.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b979e6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_index': [0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  19,\n",
       "  22,\n",
       "  25,\n",
       "  27,\n",
       "  29,\n",
       "  33,\n",
       "  34],\n",
       " 'similarity': 0.67138671875,\n",
       " 'input_id': 198,\n",
       " 'output_id': 32313}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['0']['Token'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['alpaca', 'gsm8k', 'math_infini', 'mt-bench', 'sum', 'vicuna-bench']\n",
    "models = ['Qwen3-8B', 'Qwen3-14B']\n",
    "import os, json\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        train_data_path = f'./train_data/{dataset}_{model}_data_None_None.json'\n",
    "        if os.path.exists(train_data_path):\n",
    "            with open(train_data_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                tot = 0\n",
    "                for key, value in data.items():\n",
    "                    tot += value['avg_len']\n",
    "                print(f'{dataset}_{model}: {tot / len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for key, value in data.items():    \n",
    "    tot += len(value['Token'])\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.tensor([[151667]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.item() == data['0']['Token'][0]['input_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213692cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id = 0\n",
    "for key, value in data.items():\n",
    "    for idx, token in enumerate(value['Token']):\n",
    "        input_id = token['input_id']\n",
    "        if  input_id != output_id:\n",
    "            print(value['Token'][idx-1])\n",
    "            print(idx, input_id, output_id)\n",
    "        output_id = token['output_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_logits = model.lm_head(fake_last_hidden_states[3])\n",
    "true_logits = model.lm_head(true_last_hidden_states[4])\n",
    "fake_token = torch.argmax(fake_logits, dim=-1)\n",
    "true_token = torch.argmax(true_logits, dim=-1)\n",
    "print(fake_token, true_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
    "]\n",
    "messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How are you\"\n",
    "        })\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfff494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "min_dtype = torch.finfo(torch.float16).min\n",
    "mask = torch.full((1, 117), fill_value=min_dtype, dtype=torch.float16)\n",
    "cache_pos = torch.arange(117,118)\n",
    "dag = torch.arange(117) > cache_pos.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/xujiaming/xujiaming/Paper/SpecMoD/data/alpaca_Qwen3-8B_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    lst = []\n",
    "    for key, value in data.items():\n",
    "        lst.append(value['avg_len'])\n",
    "    print(sum(lst) / len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6747cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for key, value in data.items():\n",
    "    lst.append(value['avg_len'])\n",
    "print(sum(lst) / len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xujiaming/xujiaming/Paper/SpecMoD/data/alpaca_Qwen3-8B_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    lst = []\n",
    "    ground_truth = []\n",
    "    for q_id, q_re in data.items():\n",
    "        for token_id, token_value in q_re['Token'].items():\n",
    "            lst.append(eval(token_id))\n",
    "            ground_truth.append(token_value['layer_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae652b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from model.qwen3_model import Spec_Qwen3ForCausalLM\n",
    "\n",
    "model = Spec_Qwen3ForCausalLM.from_pretrained(f\"/share/others/public_models/Qwen3-14B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data_emb = model.model.embed_tokens(torch.tensor(lst)).detach()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdeba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[] for i in range(10)] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25623ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[100] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0].append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1] = a[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a90ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "v1 = torch.tensor([1., 2., 3.]).unsqueeze(0).unsqueeze(0)\n",
    "v2 = torch.tensor([1., 1., 3.]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# 对于 1D 向量，我们需要在 dim=0 上计算\n",
    "similarity_1d = F.cosine_similarity(v1, v2, dim= -1).mean()\n",
    "print(f\"v1: {v1}\")\n",
    "print(f\"v2: {v2}\")\n",
    "print(f\"1D 向量余弦相似度: {similarity_1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1.,2.,3.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b874614",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(a).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb653dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class PathPredictorMLP(nn.Module):\n",
    "    def __init__(self, n_layers, llm_hidden_dim, mlp_internal_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = llm_hidden_dim \n",
    "        self.output_dim = n_layers\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, mlp_internal_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(mlp_internal_dim), \n",
    "            nn.Linear(mlp_internal_dim, self.output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "predictor = PathPredictorMLP(\n",
    "    n_layers=36,\n",
    "    llm_hidden_dim=4096,\n",
    "    mlp_internal_dim=1024,)\n",
    "predictor.load_state_dict(torch.load(\"/home/xujiaming/xujiaming/Paper/SpecMoD/path_predictor_mlp_baseline.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 1, 4096)\n",
    "logits = predictor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edede12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21f26f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3079208152.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31ma[[1:4, 7:9]]\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127688b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
