{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "730a293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
       "          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM,Qwen3ForCausalLM\n",
    "# /share/public/public_models/Qwen3-14B/\n",
    "# /share/others/public_models/Qwen3-14B/\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/inspire/hdd/global_public/public_models/Qwen/Qwen3-14B/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/inspire/hdd/global_public/public_models/Qwen/Qwen3-14B/\")\n",
    "model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./train_data/vicuna-bench_Qwen3-14B_data_0_2.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1edee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['1']['Token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baff1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_name = 'Qwen3-14B'\n",
    "dataset = 'vicuna-bench'\n",
    "begin = '0'\n",
    "end = '2'\n",
    "cur_hidden_states = torch.load(f'./train_data_backup/{dataset}_{model_name}_cur_hidden_states_{begin}_{end}.pt')\n",
    "fake_last_hidden_states = torch.load(f'./train_data_backup/{dataset}_{model_name}_fake_last_hidden_states_{begin}_{end}.pt')\n",
    "true_last_hidden_states = torch.load(f'./train_data_backup/{dataset}_{model_name}_true_last_hidden_states_{begin}_{end}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a69ca5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 1, 5120])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf84e564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 1, 5120])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e62080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 5120])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2e39893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"./train_data/{dataset}_{model_name}_data_{begin}_{end}.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "213692cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "1517\n",
      "1756\n",
      "2182\n",
      "2402\n",
      "2563\n",
      "3020\n",
      "3726\n",
      "3981\n",
      "4175\n",
      "4497\n",
      "4767\n",
      "4953\n",
      "5203\n",
      "5793\n",
      "6034\n",
      "6140\n",
      "6429\n",
      "6652\n",
      "7029\n",
      "7639\n",
      "8114\n",
      "8633\n",
      "9423\n",
      "9782\n",
      "9993\n",
      "10940\n",
      "11541\n",
      "11840\n",
      "12369\n",
      "12578\n",
      "12779\n",
      "13297\n",
      "13854\n",
      "14006\n",
      "14414\n",
      "14600\n",
      "14789\n",
      "15085\n",
      "15501\n",
      "16022\n",
      "16598\n",
      "17008\n",
      "17492\n",
      "17937\n",
      "18636\n",
      "19045\n",
      "19433\n",
      "19606\n",
      "20207\n",
      "20685\n",
      "21236\n",
      "21488\n",
      "21927\n",
      "22466\n",
      "23465\n",
      "23598\n",
      "23733\n",
      "24058\n",
      "24282\n",
      "24469\n",
      "24609\n",
      "24808\n",
      "25265\n",
      "25536\n",
      "25720\n",
      "26233\n",
      "26510\n",
      "27000\n",
      "27465\n",
      "27798\n",
      "28062\n",
      "28314\n",
      "28563\n",
      "28741\n",
      "29110\n",
      "29503\n",
      "29883\n",
      "30314\n",
      "30580\n"
     ]
    }
   ],
   "source": [
    "for key, value in data.items():\n",
    "    print(len(value['Token']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b990f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([279]) tensor([279])\n"
     ]
    }
   ],
   "source": [
    "fake_logits = model.lm_head(fake_last_hidden_states[12])\n",
    "true_logits = model.lm_head(true_last_hidden_states[14])\n",
    "fake_token = torch.argmax(fake_logits, dim=-1)\n",
    "true_token = torch.argmax(true_logits, dim=-1)\n",
    "print(fake_token, true_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0315acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
    "]\n",
    "messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How are you\"\n",
    "        })\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6860c806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 117])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfff494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "min_dtype = torch.finfo(torch.float16).min\n",
    "mask = torch.full((1, 117), fill_value=min_dtype, dtype=torch.float16)\n",
    "cache_pos = torch.arange(117,118)\n",
    "dag = torch.arange(117) > cache_pos.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513e8a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81c5d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.49907672039015\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/xujiaming/xujiaming/Paper/SpecMoD/data/alpaca_Qwen3-8B_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    lst = []\n",
    "    for key, value in data.items():\n",
    "        lst.append(value['avg_len'])\n",
    "    print(sum(lst) / len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6747cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.49907672039015\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for key, value in data.items():\n",
    "    lst.append(value['avg_len'])\n",
    "print(sum(lst) / len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9febea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xujiaming/xujiaming/Paper/SpecMoD/data/alpaca_Qwen3-8B_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    lst = []\n",
    "    ground_truth = []\n",
    "    for q_id, q_re in data.items():\n",
    "        for token_id, token_value in q_re['Token'].items():\n",
    "            lst.append(eval(token_id))\n",
    "            ground_truth.append(token_value['layer_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae652b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:35<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from model.qwen3_model import Spec_Qwen3ForCausalLM\n",
    "\n",
    "model = Spec_Qwen3ForCausalLM.from_pretrained(f\"/share/others/public_models/Qwen3-14B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e6cd660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 5120,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 17408,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 40,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 40,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5fb546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_emb = model.model.embed_tokens(torch.tensor(lst)).detach()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fdeba6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([237648, 5120])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1904cddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 81,\n",
       " 'category': 'writing',\n",
       " 'turns': ['Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.',\n",
       "  'Rewrite your previous response. Start every sentence with the letter A.']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[] for i in range(10)] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25623ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[100] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69e4cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c61f422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0].append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd68e449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5], [5], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], []]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16fa8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1] = a[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a90ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c5c64b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: tensor([[[1., 2., 3.]]])\n",
      "v2: tensor([[[1., 1., 3.]]])\n",
      "1D 向量余弦相似度: 0.9669874906539917\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "v1 = torch.tensor([1., 2., 3.]).unsqueeze(0).unsqueeze(0)\n",
    "v2 = torch.tensor([1., 1., 3.]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# 对于 1D 向量，我们需要在 dim=0 上计算\n",
    "similarity_1d = F.cosine_similarity(v1, v2, dim= -1).mean()\n",
    "print(f\"v1: {v1}\")\n",
    "print(f\"v2: {v2}\")\n",
    "print(f\"1D 向量余弦相似度: {similarity_1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7096a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1.,2.,3.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b874614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb653dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'81': {'Prompt': [151644, 8948, 198, 2610, 525, 264, 10950, 11, 48050, 323, 10745, 17847, 13, 23240, 4226, 438, 1492, 3641, 438, 3204, 11, 1393, 1660, 6092, 13, 220, 4615, 11253, 1265, 537, 2924, 894, 27756, 11, 88635, 11, 24207, 11, 63782, 11, 20836, 11, 11406, 11, 476, 11816, 2213, 13, 5209, 5978, 429, 697, 14507, 525, 39318, 73215, 323, 6785, 304, 6993, 382, 2679, 264, 3405, 1558, 537, 1281, 894, 5530, 11, 476, 374, 537, 2097, 1832, 55787, 11, 10339, 3170, 4518, 315, 35764, 2494, 537, 4396, 13, 1416, 498, 1513, 944, 1414, 279, 4226, 311, 264, 3405, 11, 4486, 1513, 944, 4332, 895, 1995, 13, 151645, 198, 151644, 872, 198, 70492, 458, 22570, 5821, 5010, 1736, 911, 264, 3213, 8411, 311, 27521, 11, 38586, 12752, 11449, 323, 1969, 12, 4060, 38491, 13, 151645, 198, 151644, 77091, 198], 'Token': {'198': {'layer_index': [19, 20, 29, 30, 35, 36, 37, 39], 'similarity': 0.11242804676294327}, '32313': {'layer_index': [0, 1, 5, 8, 9, 11, 12, 13, 16, 21, 26, 28, 29, 30, 38, 39], 'similarity': 0.35404250025749207}, '11': {'layer_index': [0, 5, 6, 11, 17, 29, 32], 'similarity': 0.1374615579843521}, '279': {'layer_index': [0, 7, 8, 9, 10, 11, 13, 14, 15, 16, 26, 34], 'similarity': 0.1265527606010437}, '1196': {'layer_index': [0, 4, 6, 8, 9, 11, 12, 13, 14, 15, 20, 21, 23, 29, 30, 33], 'similarity': 0.22095587849617004}, '6801': {'layer_index': [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 20, 26, 27, 30, 34, 38, 39], 'similarity': 0.2972051501274109}, '752': {'layer_index': [0, 4, 8, 9, 10, 13, 14, 16, 17, 18, 23, 27, 28, 29, 30, 31, 32, 38, 39], 'similarity': 0.37451279163360596}, '311': {'layer_index': [0, 5, 6, 8, 9, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.7261499166488647}, '30335': {'layer_index': [19, 20, 30, 32, 35, 36, 37, 38, 39], 'similarity': 0.28924721479415894}, '458': {'layer_index': [0, 1, 4, 7, 8, 9, 16, 17, 18, 23, 26, 34], 'similarity': 0.19919896125793457}, '22570': {'layer_index': [0, 2, 4, 8, 9, 10, 13, 14, 15, 16, 17, 23, 30, 31, 32, 34, 37, 38, 39], 'similarity': 0.5864161252975464}, '5821': {'layer_index': [0, 2, 4, 8, 9, 10, 13, 14, 15, 20, 23, 29, 32, 38, 39], 'similarity': 0.25045648217201233}, '5010': {'layer_index': [0, 5, 6, 8, 13, 14, 16, 17, 20, 29, 31, 32], 'similarity': 0.1956930160522461}, '1736': {'layer_index': [0, 5, 8, 9, 13, 14, 15, 16, 23, 29, 30, 34, 37], 'similarity': 0.2655996084213257}, '911': {'layer_index': [0, 3, 5, 8, 9, 13, 14, 15, 16, 17, 22, 26, 29], 'similarity': 0.2998620867729187}, '264': {'layer_index': [0, 4, 5, 8, 9, 11, 13, 14, 15, 17, 25, 32, 38], 'similarity': 0.1909940540790558}, '3213': {'layer_index': [0, 4, 6, 8, 9, 13, 14, 15, 16, 17, 23, 31, 32, 33, 34, 35, 38, 39], 'similarity': 0.5816769599914551}, '8411': {'layer_index': [0, 5, 8, 9, 10, 13, 16, 17, 26, 32, 38, 39], 'similarity': 0.2547260522842407}, '27521': {'layer_index': [0, 1, 5, 8, 9, 10, 13, 14, 15, 16, 25, 26, 34, 35, 36, 38, 39], 'similarity': 0.4537694454193115}, '21080': {'layer_index': [0, 4, 8, 9, 10, 11, 12, 16, 17, 20, 23, 24, 29, 30, 31, 34, 37, 39], 'similarity': 0.35366955399513245}, '389': {'layer_index': [0, 5, 8, 9, 10, 13, 14, 15, 20, 21, 26, 29], 'similarity': 0.3398711383342743}, '12752': {'layer_index': [19, 20, 21, 23, 24, 25, 26, 27, 32, 33, 35, 37, 38, 39], 'similarity': 0.17679505050182343}, '11449': {'layer_index': [0, 2, 6, 8, 9, 13, 14, 17, 20, 21, 22, 26, 32, 34, 35, 37, 39], 'similarity': 0.2420908808708191}, '323': {'layer_index': [0, 4, 5, 8, 9, 17, 22, 23, 26], 'similarity': 0.29077374935150146}, '1969': {'layer_index': [0, 4, 8, 9, 10, 11, 17, 18, 23, 26, 32], 'similarity': 0.18798606097698212}, '12': {'layer_index': [0, 4, 6, 8, 9, 13, 14, 16, 30, 34], 'similarity': 0.07897529006004333}, '4060': {'layer_index': [0, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 23, 26, 31, 33, 35, 37, 38, 39], 'similarity': 0.47335612773895264}, '38491': {'layer_index': [0, 2, 4, 5, 8, 9, 13, 14, 26, 34, 38, 39], 'similarity': 0.32722312211990356}, '13': {'layer_index': [0, 6, 8, 9, 10, 13, 14, 15, 23, 24, 26, 34, 38], 'similarity': 0.1784600019454956}, '6771': {'layer_index': [0, 4, 6, 8, 9, 11, 13, 14, 15, 23, 29, 31, 32, 33, 35, 38, 39], 'similarity': 0.5137515068054199}, '1191': {'layer_index': [0, 1, 7, 8, 9, 10, 13, 14, 15, 16, 23, 26, 30, 31, 32, 33, 37, 38, 39], 'similarity': 0.5294590592384338}, '553': {'layer_index': [0, 4, 6, 8, 9, 12, 13, 14, 15, 23, 26, 29, 31, 38], 'similarity': 0.22051571309566498}, '86781': {'layer_index': [0, 1, 4, 8, 9, 10, 12, 13, 23, 24, 29, 30, 33], 'similarity': 0.2593677043914795}, '287': {'layer_index': [0, 9], 'similarity': 0.12431588023900986}, '1376': {'layer_index': [0, 1, 4, 8, 9, 10, 13, 14, 15, 16, 17, 34, 35, 38, 39], 'similarity': 0.37541699409484863}, '5424': {'layer_index': [0, 4, 8, 9, 10, 13, 14, 15, 16, 26, 31, 32, 33, 35, 38], 'similarity': 0.2290743738412857}, '429': {'layer_index': [0, 5, 8, 9, 11, 13, 14, 15, 16, 23, 24, 25, 35], 'similarity': 0.1972230076789856}, '1281': {'layer_index': [0, 1, 4, 8, 9, 10, 13, 15, 16, 22, 24, 25, 30, 31, 33, 34, 35, 37, 38, 39], 'similarity': 0.7477525472640991}, '4911': {'layer_index': [0, 1, 4, 6, 8, 9, 14, 15, 16, 22, 25, 28, 31, 34], 'similarity': 0.31674492359161377}, '5512': {'layer_index': [0, 4, 6, 8, 9, 10, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.7680370807647705}, '29000': {'layer_index': [0, 5, 6, 8, 9, 14, 15, 16, 17, 22, 26, 30, 31, 32, 38, 39], 'similarity': 0.5141988396644592}, '5577': {'layer_index': [0, 5, 6, 7, 8, 9, 14, 15, 16, 17, 20, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38, 39], 'similarity': 0.741859495639801}, '2293': {'layer_index': [0, 1, 7, 9, 10, 13, 14, 20, 30, 33, 38], 'similarity': 0.24728532135486603}, '18532': {'layer_index': [0, 1, 6, 8, 9, 10, 13, 17, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.847152590751648}, '525': {'layer_index': [0, 4, 8, 9, 14, 17, 20, 21, 22, 24, 25, 29, 32, 35], 'similarity': 0.3078998923301697}, '3807': {'layer_index': [0, 1, 6, 8, 9, 13, 14, 15, 16, 20, 21, 26, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39], 'similarity': 0.7523927092552185}, '1075': {'layer_index': [0, 8, 9, 10, 13, 14, 23, 24, 25, 26, 27, 34, 35, 37, 38, 39], 'similarity': 0.42970335483551025}, '506': {'layer_index': [0, 5, 6, 9, 10, 13, 14, 15, 16, 17, 31, 38, 39], 'similarity': 0.2680497467517853}, '26695': {'layer_index': [0, 4, 5, 6, 8, 13, 14, 15, 16, 17, 20, 23, 26, 27, 30, 32, 33, 38, 39], 'similarity': 0.37693434953689575}, '92450': {'layer_index': [0, 4, 8, 9, 10, 13, 15, 16, 17, 21, 26, 30, 31, 35, 37, 38, 39], 'similarity': 0.613211989402771}, '6164': {'layer_index': [0, 4, 8, 9, 10, 11, 13, 14, 17, 18, 21, 26, 29, 30, 31, 33, 35, 36, 37, 38, 39], 'similarity': 0.7703249454498291}, '10720': {'layer_index': [0, 1, 6, 9, 14, 15, 26, 29, 30, 31, 32, 33, 35, 37, 38, 39], 'similarity': 0.48723697662353516}, '730': {'layer_index': [0, 4, 8, 9, 10, 13, 14, 20, 21, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39], 'similarity': 0.7922715544700623}, '2863': {'layer_index': [0, 4, 5, 6, 8, 9, 13, 14, 20, 23, 30, 31, 32, 35, 37, 38, 39], 'similarity': 0.44801151752471924}, '2143': {'layer_index': [0, 3, 4, 6, 8, 9, 13, 14, 18, 23, 27, 28, 29, 30, 31, 32, 37, 38, 39], 'similarity': 0.527580738067627}, '8886': {'layer_index': [0, 5, 7, 9, 11, 13, 14, 15, 23, 24, 26, 29, 30, 34, 35, 38], 'similarity': 0.2521148920059204}, '702': {'layer_index': [0, 1, 6, 8, 9, 13, 14, 16, 17, 20, 22, 26, 28, 29, 31, 32, 33, 38, 39], 'similarity': 0.5576555728912354}, '1181': {'layer_index': [0, 2, 5, 9, 10, 13, 14, 15, 16, 26, 28, 30, 31, 33, 35, 37, 38], 'similarity': 0.3015808165073395}, '1828': {'layer_index': [0, 2, 6, 8, 13, 14, 16, 23, 30, 33, 35, 37, 38], 'similarity': 0.17266212403774261}, '46711': {'layer_index': [0, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 26, 30, 31, 32, 33, 34, 35, 37, 39], 'similarity': 0.49082672595977783}, '10696': {'layer_index': [0, 1, 7, 9, 10, 11, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.7105796337127686}, '358': {'layer_index': [0, 1, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.8415930271148682}, '1265': {'layer_index': [0, 1, 4, 7, 8, 9, 12, 13, 14, 23, 24, 31, 34], 'similarity': 0.196170374751091}, '3735': {'layer_index': [0, 1, 7, 8, 9, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.8329291343688965}, '2421': {'layer_index': [0, 4, 6, 8, 9, 11, 13, 14, 15, 16, 26, 31, 32, 33, 35, 36, 37, 38, 39], 'similarity': 0.5625238418579102}, '21314': {'layer_index': [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.9272559881210327}, '504': {'layer_index': [0, 3, 5, 8, 9, 14, 15, 16, 17, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 35, 37, 38, 39], 'similarity': 0.6984801888465881}, '2155': {'layer_index': [0, 5, 8, 9, 10, 13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 31, 34, 35, 37, 38, 39], 'similarity': 0.6400660276412964}, '2968': {'layer_index': [0, 1, 4, 8, 9, 10, 13, 15, 16, 20, 21, 24, 26, 28, 29, 31, 32, 33, 35, 37, 38, 39], 'similarity': 0.6999678611755371}, '1632': {'layer_index': [0, 2, 6, 8, 9, 10, 11, 13, 14, 15, 17, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], 'similarity': 0.8737574219703674}, '64218': {'layer_index': [0, 3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 25, 34], 'similarity': 0.1411704123020172}, '1651': {'layer_index': [0, 3, 5, 6, 8, 9, 13, 14, 17, 22, 25, 28, 29, 30, 38], 'similarity': 0.25042492151260376}, '382': {'layer_index': [0, 4, 8, 9, 11, 13, 14, 16, 17, 23, 25], 'similarity': 0.21750915050506592}, '34': {'layer_index': [0, 4, 6, 8, 9, 11, 15, 16, 17, 23, 24, 29, 30, 31, 32, 35, 37, 38, 39], 'similarity': 0.653022289276123}, '43447': {'layer_index': [0, 4, 5, 8, 9, 10, 13, 14, 16, 17, 20, 21, 22, 24, 26, 32, 33, 35], 'similarity': 0.2384141981601715}, '2989': {'layer_index': [0, 1, 6, 8, 9, 10, 16, 17, 20, 24, 25, 26, 30, 31, 32, 37, 38, 39], 'similarity': 0.5748763084411621}}, 'avg_len': 16.19191919191919}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1d9683b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class PathPredictorMLP(nn.Module):\n",
    "    def __init__(self, n_layers, llm_hidden_dim, mlp_internal_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = llm_hidden_dim \n",
    "        self.output_dim = n_layers\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, mlp_internal_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(mlp_internal_dim), \n",
    "            nn.Linear(mlp_internal_dim, self.output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "predictor = PathPredictorMLP(\n",
    "    n_layers=36,\n",
    "    llm_hidden_dim=4096,\n",
    "    mlp_internal_dim=1024,)\n",
    "predictor.load_state_dict(torch.load(\"/home/xujiaming/xujiaming/Paper/SpecMoD/path_predictor_mlp_baseline.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "977f662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PathPredictorMLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=1024, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a58b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 1, 4096)\n",
    "logits = predictor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed1c2482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False,  True, False,  True, False,  True, False,  True, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False,  True, False, False, False,\n",
       "          False,  True, False, False,  True,  True]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edede12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.EAGLE_model import Model\n",
    "\n",
    "\n",
    "Ori_model_path = \"/share/others/public_models/Qwen3-8B\"\n",
    "Spec_model_path = \"/home/xujiaming/xujiaming/models/qwen3_8b_eagle3\"\n",
    "model = Model.from_pretrained(Spec_model_path=Spec_model_path, Ori_model_path=Ori_model_path, dtype=torch.float16, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec94c6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embed_tokens): Embedding(151936, 4096)\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  (midlayer): LlamaDecoderLayeremb(\n",
       "    (self_attn): LlamaAttention(\n",
       "      (q_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      (k_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "      (v_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "      (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): LlamaMLP(\n",
       "      (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "      (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "      (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "    (hidden_norm): LlamaRMSNorm()\n",
       "    (input_layernorm): LlamaRMSNorm()\n",
       "    (post_attention_layernorm): LlamaRMSNorm()\n",
       "  )\n",
       "  (fc): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "  (norm): LlamaRMSNorm()\n",
       "  (logsoftmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83636faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
